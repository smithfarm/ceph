13.2.7
======

* The MDS cache trimming is now throttled. Dropping the MDS cache
  via the `ceph tell mds.<foo> cache drop` command or large reductions in the
  cache size will no longer cause service unavailability.

* The CephFS MDS behavior with recalling caps has been significantly improved
  to not attempt recalling too many caps at once, leading to instability.
  MDS with a large cache (64GB+) should be more stable.

* MDS now provides a config option "mds_max_caps_per_client" (default: 1M) to
  limit the number of caps a client session may hold. Long running client
  sessions with a large number of caps have been a source of instability in the
  MDS when all of these caps need to be processed during certain session
  events. It is recommended to not unnecessarily increase this value.

* The MDS config mds_recall_state_timeout has been removed. Late client recall
  warnings are now generated based on the number of caps the MDS has recalled
  which have not been released. The new configs mds_recall_warning_threshold
  (default: 32K) and mds_recall_warning_decay_rate (default: 60s) sets the
  threshold for this warning.

* The `cache drop` admin socket command has been removed. The `ceph tell mds.X
  cache drop` remains.

* RGW: radosgw-admin introduces two subcommands that allow the
  managing of expire-stale objects that might be left behind after a
  bucket reshard in earlier versions of RGW. One subcommand lists such
  objects and the other deletes them. Read the troubleshooting section
  of the dynamic resharding docs for details.

* A health warning is now generated if the average osd heartbeat ping
  time exceeds a configurable threshold for any of the intervals
  computed.  The OSD computes 1 minute, 5 minute and 15 minute
  intervals with average, minimum and maximum values.  New configuration
  option ``mon_warn_on_slow_ping_ratio`` specifies a percentage of
  ``osd_heartbeat_grace`` to determine the threshold.  A value of zero
  disables the warning.  New configuration option
 ``mon_warn_on_slow_ping_time`` specified in milliseconds over-rides the
  computed value, causes a warning
  when OSD heartbeat pings take longer than the specified amount.
  New admin command ``ceph daemon mgr.# dump_osd_network [threshold]`` command will
  list all connections with a ping time longer than the specified threshold or
  value determined by the config options, for the average for any of the 3 intervals.
  New admin command ``ceph daemon osd.# dump_osd_network [threshold]`` will
  do the same but only including heartbeats initiated by the specified OSD.


13.2.9
======

* The configuration value ``osd_calc_pg_upmaps_max_stddev`` used for upmap
  balancing has been removed. Instead use the mgr balancer config
  ``upmap_max_deviation`` which now is an integer number of PGs of deviation
  from the target PGs per OSD.  This can be set with a command like
  ``ceph config set mgr mgr/balancer/upmap_max_deviation 2``.  The default
  ``upmap_max_deviation`` is 1.  There are situations where crush rules
  would not allow a pool to ever have completely balanced PGs.  For example, if
  crush requires 1 replica on each of 3 racks, but there are fewer OSDs in 1 of
  the racks.  In those cases, the configuration value can be increased.

* The 'cephfs-data-scan scan_links' now automatically repair inotables.

